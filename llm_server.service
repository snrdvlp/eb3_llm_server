[Unit]
Description=LLM Server (vLLM API)
After=network.target

[Service]
WorkingDirectory=/home/eb3-brayan/
ExecStart=/usr/bin/python3 -m vllm.entrypoints.openai.api_server \
    --model Qwen/Qwen2.5-7B-Instruct \
    --host 0.0.0.0 \
    --port 8000 \
    --quantization bitsandbytes \
    --tensor-parallel-size 1
    --max-num-seqs 16 \
    --uvicorn-log-level debug

Restart=always
RestartSec=5

User=eb3-brayan
Group=eb3-brayan

LimitNOFILE=65535
TimeoutStartSec=300
TimeoutStopSec=60
StandardOutput=journal
StandardError=journal
[Install]
WantedBy=multi-user.target